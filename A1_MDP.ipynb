{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_MDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarsh-TG/AashiProject/blob/main/A1_MDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNuPEpmsxpu"
      },
      "source": [
        "import numpy as np\n",
        "#import quantecon as qe\n",
        "%matplotlib inline\n",
        "from scipy import linalg, optimize\n",
        "from scipy.stats import beta\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (10,6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X1VItOKtCrL"
      },
      "source": [
        "#MDP Model Formulation\n",
        "#data\n",
        "N=3\n",
        "M=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2w0xGcHtF9V"
      },
      "source": [
        "#set of decision dates is T = {1, ..., N} \n",
        "T = np.linspace(1, N, num=N, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVA_sBGttHc_"
      },
      "source": [
        "#set of states: inventory stock at start of a period S = {0, 1, ..., M}\n",
        "S = np.linspace(0, M, num=M+1, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zugNy3s7tJEY"
      },
      "source": [
        "#set of actions in state s \n",
        "def A(s):\n",
        "    return np.linspace(0, M - s, num=M-s+1, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SwyW5qWtKlT"
      },
      "source": [
        "#stochastic specification of demand where p[j] is the probability that demand is equal to j units\n",
        "p = np.array([0.25, 0.5, 0.25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7GAE_fotMLe"
      },
      "source": [
        "#manager's revenue when demand of u units is satisfied with current inventory levels\n",
        "def f(u):\n",
        "    return 8*u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUbhUCMptOAK"
      },
      "source": [
        "#manager's expected revenue as a function of current period inventory u \n",
        "def F(u):\n",
        "    if u==0:\n",
        "       return 0\n",
        "    else:\n",
        "       return f(np.linspace(0, u-1, num=u, dtype=int))@p[0:u] + f(u)*(1 - np.cumsum(p)[u-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Php7PsrytRkc"
      },
      "source": [
        "#manager's inventory holding costs\n",
        "def h(u):\n",
        "    return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsnasF7DtT33"
      },
      "source": [
        "#inventory value at terminal date\n",
        "def g(u):\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkEEjYOZtftm"
      },
      "source": [
        "#manager's inventory ordering costs\n",
        "def O(u):\n",
        "    if u==0:\n",
        "       return 0\n",
        "    else:\n",
        "       return K + 2*u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKCSDYO_thIZ"
      },
      "source": [
        "#transition probabilities to inventory stock of j next period when the inventory stock current period is s and\n",
        "#an inventory order of a has been placed in the current period; s+a-j is the demand in the current period\n",
        "def tp(j,s,a):\n",
        "    if s+a-j < 0:   \n",
        "        return 0\n",
        "    elif s+a-j >= 0 and j > 0:\n",
        "        return p[s+a-j]\n",
        "    elif j == 0:\n",
        "        return 1 - np.cumsum(p)[s+a-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha01prfItkF1"
      },
      "source": [
        "#expected rewards = expected revenue - ordering costs - holding costs\n",
        "def r(s,a):\n",
        "    return F(s+a) - O(a) - h(s+a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTAD3Fhdtlye"
      },
      "source": [
        "#terminal reward = inventory value at terminal date\n",
        "def r_4(s):\n",
        "    return g(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1RNufy0trrH"
      },
      "source": [
        "# this function takes value u(s,a) at time t and finds the optimal value and optimal acion\n",
        "def maximize_rew(u):\n",
        "  optimal_reward = []\n",
        "\n",
        "  for key, value in u.items():\n",
        "    #print('Items :',key,value)\n",
        "    max = value[0]\n",
        "    for val in value:\n",
        "      if max['r'] < val['r']:\n",
        "        max = val\n",
        "    optimal_reward.append(max)\n",
        "\n",
        " # print('Optimal Reward at state',s, ' time',t ,'is, optimal_reward') ######## check\n",
        "\n",
        "  rew_list = []\n",
        "  action_list = []\n",
        "\n",
        "  for i in optimal_reward:\n",
        "    rew = i['r']\n",
        "    rew_list.append(rew)\n",
        "    _action = i['a']\n",
        "    action_list.append(_action) # lists all the action for time t and state s\n",
        "  \n",
        "  U.append(rew_list)\n",
        "  action.append(action_list)\n",
        "\n",
        "  return U, action\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Eg8NBO-tpQJ"
      },
      "source": [
        "# step1: Set T=N and Un*(s) = Rn(Sn)\n",
        "U=[[]]\n",
        "action = [[]]\n",
        "for s in S:\n",
        "    U[0].append(r_4(s)) \n",
        "    action[0].append(r_4(s))\n",
        "\n",
        "u={}\n",
        "K=0\n",
        "# step2: for t = t-1 find optimal reward and optimal action\n",
        "for t in range (N,0,-1):\n",
        "    _s = {}\n",
        "    for s in S:\n",
        "        temparr = []\n",
        "        for a in A(s):  # calculates U_t(s_t,a_t) = r_t(s_t,a_t) + sum_over_states(p_t(j|s_t,a_t)*U_t+1(j))\n",
        "            #print(s,a)\n",
        "            summation = 0 \n",
        "            for j in S:\n",
        "                #print(\"j=\",j)\n",
        "                tp_product_nextreward = tp(j,s,a)*U[N-t][j] \n",
        "                #print('temp1'  ,temp1)\n",
        "                summation += tp_product_nextreward\n",
        "\n",
        "            reward = r(s,a) + summation\n",
        "\n",
        "# Dictionary stores u[t] = (s,a,u(s,a)) for every time period\n",
        "            ndict = {'s':s,'a':a,'r':reward}\n",
        "            temparr.append(ndict)\n",
        "        _s[s] = (temparr)     \n",
        "    u[t] = _s \n",
        "    U,action = maximize_rew(_s) # to find optimal values and optimal actions\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKgJrtXXxmqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae68957e-021d-43e7-c2f8-ce4f238728b6"
      },
      "source": [
        "print(\"The array depict Optimal Rewards as [r_t=N(s=0, s=1 ... ,s=3)],[r_t=N-1(s=0, s=1 ... ,s=3)],....,[r_t=1(s=0, s=1 ... ,s=3)] \")\n",
        "print(U)\n",
        "print(\"The array depict Optimal Actions as [a_t=N(s=0, s=1 ... ,s=3)],[a_t=N-1(s=0, s=1 ... ,s=3)],....,[a_t=1(s=0, s=1 ... ,s=3)] \")\n",
        "print(action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The array depict Optimal Rewards as [r_t=N(s=0, s=1 ... ,s=3)],[r_t=N-1(s=0, s=1 ... ,s=3)],....,[r_t=1(s=0, s=1 ... ,s=3)] \n",
            "[[0, 0, 0, 0], [3.0, 5.0, 6.0, 5.0], [6.75, 8.75, 10.75, 10.5], [10.75, 12.75, 14.75, 15.1875]]\n",
            "The array depict Optimal Actions as [a_t=N(s=0, s=1 ... ,s=3)],[a_t=N-1(s=0, s=1 ... ,s=3)],....,[a_t=1(s=0, s=1 ... ,s=3)] \n",
            "[[0, 0, 0, 0], [1, 0, 0, 0], [2, 1, 0, 0], [2, 1, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJUBdLc6dyC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doDiS6gFcjdy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJDiNKScjqw"
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w92BKwLpclaL"
      },
      "source": [
        "# MDP Model Formulation\n",
        "# data\n",
        "N=4\n",
        "M=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meWfRYswcnP1"
      },
      "source": [
        "# set of decision dates is T = {1, ..., N} \n",
        "T = np.linspace(1, N, num=N, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HVGixZVcupS"
      },
      "source": [
        "# set of states: inventory stock at start of a period S = {0, 1, ..., M}\n",
        "S = np.linspace(0, M, num=M+1, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJgUlsT6cwPT"
      },
      "source": [
        "# set of actions in state s \n",
        "def A(s):\n",
        "    return np.linspace(0, s, num=s, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoMj95eLcxkX"
      },
      "source": [
        "def utility(c,t):\n",
        "    try:\n",
        "      return int((0.9** t)*(math.log(c)))\n",
        "    except ValueError:\n",
        "      return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6KLDgyxg7Yo",
        "outputId": "541b4616-4824-44a7-fd5b-1bb0a38955ca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.5 , 0.25])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChUr3PQtczE8"
      },
      "source": [
        "# expected rewards = utility + interest on saving\n",
        "def r(s,a,t):\n",
        "    return int(utility(a,t) + 1.05*(s-a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAcEmxYkc0xC"
      },
      "source": [
        "# transition is deterministic j = s - a\n",
        "def tp(j,s,a):\n",
        "    if j == s-a:   \n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJIbXvo6c2Mm"
      },
      "source": [
        "# terminal reward = interest on the saving\n",
        "def r_4(s):\n",
        "    return 1.05*(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG8HPVkuc3tC"
      },
      "source": [
        "# this function takes value u(s,a) at time t and finds the optimal value and optimal acion\n",
        "def maximize_rew(u):\n",
        "  optimal_reward = []\n",
        "\n",
        "  for key, value in u.items():\n",
        "    #print('Items :',key,value)\n",
        "    max = value[0]\n",
        "    for val in value:\n",
        "        if max['r'] < val['r']:\n",
        "          max = val\n",
        "    optimal_reward.append(max)\n",
        "\n",
        " # print('Optimal Reward at state',s, ' time',t ,'is, optimal_reward') ######## check\n",
        "\n",
        "  rew_list = []\n",
        "  action_list = []\n",
        "\n",
        "  for i in optimal_reward:\n",
        "    rew = i['r']\n",
        "    rew_list.append(rew)\n",
        "    _action = i['a']\n",
        "    action_list.append(_action) # lists all the action for time t and state s\n",
        "  \n",
        "  U.append(rew_list)\n",
        "  action.append(action_list)\n",
        "\n",
        "  return U, action\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THBqLYl-c5P4"
      },
      "source": [
        "# step1: Set T=N and Un*(s) = Rn(Sn)\n",
        "U=[[]]\n",
        "action = [[]]\n",
        "for s in S:\n",
        "    U[0].append(r_4(s)) \n",
        "    action[0].append(r_4(s))\n",
        "\n",
        "u={}\n",
        "K=0\n",
        "# step2: for t = t-1 find optimal reward and optimal action\n",
        "for t in range (N,0,-1):\n",
        "    _s = {}\n",
        "    for s in S:\n",
        "        temparr = []\n",
        "        for a in A(s):  # calculates U_t(s_t,a_t) = r_t(s_t,a_t) + sum_over_states(p_t(j|s_t,a_t)*U_t+1(j))\n",
        "            #print(s,a)\n",
        "            summation = 0 \n",
        "            for j in S:\n",
        "                #print(\"j=\",j)\n",
        "                tp_product_nextreward = tp(j,s,a)*U[N-t][j] \n",
        "                #print('temp1'  ,temp1)\n",
        "                summation += tp_product_nextreward\n",
        "\n",
        "            reward = r(s,a,t) + summation\n",
        "\n",
        "# Dictionary stores u[t] = (s,a,u(s,a)) for every time period\n",
        "            ndict = {'s':s,'a':a,'r':reward}\n",
        "            temparr.append(ndict)\n",
        "        _s[s] = (temparr)     \n",
        "    u[t] = _s \n",
        "    U,action = maximize_rew(_s) # to find optimal values and optimal actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KirncXCSdT_E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}